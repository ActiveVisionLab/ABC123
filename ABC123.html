<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="Micahel A. Hobley, Victor A. Prisacariu">
  <meta name="generator" content="Jekyll v4.1.1">

  <title>Multi-Class Few-Shot Counting Dataset</title>

  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="./bootstrap.min.css"
    integrity="sha384-JcKb8q3iqJ61gNV9KGb8thSsNjpSL0n8PARn9HuZOnIxN0hoP+VmmDGMN5t9UJ0Z" crossorigin="anonymous">
</head>

<body>

  <main role="main" class="container">

    <div class="title" style="text-align:center;">
      <h1>ABC Easy as 123: A Blind Counter for Exemplar-Free <br> Multi-Class Class-agnostic Counting

      </h1>
      <h2>&
      </h2>
      <h1>MCAC: A Multi-Class Class-Agnostic Counting Dataset
      </h1>
    </div>

    <div class="col text-center">
      <p class="authors">
        <a href="https://scholar.google.co.uk/citations?user=2EftbyIAAAAJ&amp;hl=en">Michael A. Hobley</a>,
        <a href="http://www.robots.ox.ac.uk/~victor/">Victor A. Prisacariu</a><br>
        University of Oxford
      </p>
    </div>

    <div class="col text-center">
      <a class="btn btn-secondary" href="https://arxiv.org/abs/2309.04820" role="button">Paper</a>
      <a class="btn btn-secondary" href="https://github.com/ActiveVisionLab/ABC123" role="button">Code</a>
      <a class="btn btn-secondary" href="https://github.com/ActiveVisionLab/ABC123" role="button">Dataset</a>

    </div>

    <h2>ABC123 </h2>
    <div style="text-align:left;">
      Class-agnostic counting methods enumerate objects of an arbitrary class, providing tremendous utility in many
      fields.
      Prior works have limited usefulness as they require either a set of examples of the type to be counted or that the
      image contains only a single type of object. A significant factor in these shortcomings is the lack of a dataset
      to properly address counting in settings with more than one kind of object present.
      To address these issues, we propose the first Multi-class, Class-Agnostic Counting dataset (MCAC) and A Blind
      Counter (ABC123), a method that can count multiple types of objects simultaneously without using examples of type
      during training or inference.
      ABC123 introduces a new paradigm where instead of requiring exemplars to guide the enumeration, examples are found
      after the counting stage to help a user understand the generated outputs.
      We show that ABC123 outperforms contemporary methods on MCAC without the requirement of human in-the-loop
      annotations. We also show that this performance transfers to FSC-147, the standard class-agnostic counting
      dataset. </div>

    <br>
    <div style="text-align:center;">
      <img src="./multi_class_files/ABC123_example_2534708946430548.png" style="width:100%">
      ABC123 enumerates instances of multiple types of objects simultaneously without needing exemplar images. Not only
      does ABC123 not require exemplar images, it finds examples of type to aid a user in understanding the types it has
      counted.
    </div>

    <br>
    <br>


    <h2>MCAC </h2>
    <div style="text-align:center;">
      <img src="./multi_class_files/MCAC_example.png" style="width:100%">
      <b>MCAC Example</b>. Each object in the RGB image has an associated: Model ID, Class ID, Center Coordinate,
      Bounding Box and Occlusion
      Percentage.
      <p>
        More examples can be seen <a href="MCAC_examples.html"> here.</a>
      </p>

    </div>
    <br>

    <p>
      This dataset is a set of synthetic images of objects for the purpose of multi-class few-shot or class-agnostic
      counting.
    </p>
    <p>
      The classes of objects present in the Train, Test and Val splits are mutually exclusive, and where possible
      aligned with the class splits in <a href="https://github.com/ActiveVisionLab/LearningToCountAnything"> FSC-133</a>.
    <p>
      Models are taken from <a href="https://shapenet.org/"> ShapeNetSem</a>. The original model IDs and manually
      verified category labels are preserved.

    </p>

    <ul>
      <li><b>4756</b> Training images from <b>287</b> classes </li>
      <li><b>2413</b> Validation images from <b>37</b> classes </li>
      <li><b>2114</b> Testing images from <b>19</b> classes </li>
      <li>Each object is labeled with an instance, class and model number as well as its center coordinate, bounding box
        coordinates and its percentage occlusion</li>
    </ul>

    <br>

    <h2>Benchmark Results</h2>

    <table class="tg" cellpadding="10">
      </tr>
      <thead>
        <tr style="border-top:1px solid black">
          <td align="center">
            </th>
          <td align="center">
            </th>
          <td align="center" colspan="4">Val</th>
          <td align="center" colspan="4">Test</th>
        </tr>
      </thead>
      <tbody>
        <tr style="border-bottom:1px solid black">
          <td align="center">Method</td>
          <td align="center">Shots</td>
          <td align="center">MAE</td>
          <td align="center">RMSE</td>
          <td align="center">NAE</td>
          <td align="center">SRE</td>
          <td align="center">MAE</td>
          <td align="center">RMSE</td>
          <td align="center">NAE</td>
          <td align="center">SRE</td>
        </tr>

        <tr>
          <td align="left">Mean</td>
          <td align="center">N/A</td>
          <td align="center"> 39.87 </td>
          <td align="center"> 53.56 </td>
          <td align="center"> 3.07 </td>
          <td align="center"> 11.40 </td>
          <td align="center"> 42.67 </td>
          <td align="center"> 59.68 </td>
          <td align="center"> 2.79 </td>
          <td align="center"> 10.93 </td>
        </tr>

        <tr style="border-bottom:1px solid black">
          <td align="left">Median</td>
          <td align="center">N/A</td>
          <td align="center">36.25 </td>
          <td align="center"> 58.15 </td>
          <td align="center"> 1.51 </td>
          <td align="center"> 6.70 </td>
          <td align="center"> 39.81 </td>
          <td align="center"> 65.36 </td>
          <td align="center"> 1.38 </td>
          <td align="center"> 6.73</td>
        </tr>
        <tr>
          <td align="left"><a href="https://arxiv.org/pdf/2104.08391.pdf">FamNet</a></td>
          <td align="center">3</td>
          <td align="center"> 24.76 </td>
          <td align="center"> 41.12 </td>
          <td align="center"> 1.12 </td>
          <td align="center"> 6.86 </td>
          <td align="center"> 26.40 </td>
          <td align="center"> 45.52 </td>
          <td align="center"> 1.04 </td>
          <td align="center"> 6.87 </td>
        </tr>

        <tr>
          <td align="left"><a href="https://arxiv.org/abs/2203.08354.pdf">BMNet</a></td>
          <td align="center">3</td>
          <td align="center"> 15.83 </td>
          <td align="center"> 27.07 </td>
          <td align="center"> 0.71 </td>
          <td align="center"> 4.97 </td>
          <td align="center"> 17.29 </td>
          <td align="center"> 29.83 </td>
          <td align="center"> 0.75 </td>
          <td align="center"> 6.08 </td>
        </tr>
        <tr>

          <td align="left"><a href="https://arxiv.org/abs/2208.13721">CounTR</a></td>
          <td align="center">3</td>
          <td align="center"> 15.07 </td>
          <td align="center"> 26.26 </td>
          <td align="center"> 0.63 </td>
          <td align="center"> 4.79 </td>
          <td align="center"> 16.12 </td>
          <td align="center"> 29.28 </td>
          <td align="center"> 0.67 </td>
          <td align="center"> 5.71 </td>

        </tr>

        <tr style="border-bottom:1px solid black">
          <td align="left">ABC123</td>
          <td align="center"> 0 </td>
          <td align="center"> 8.96 </td>
          <td align="center"> 15.93 </td>
          <td align="center"> 0.29 </td>
          <td align="center"> 2.02 </td>
          <td align="center"> 9.52 </td>
          <td align="center"> 17.64 </td>
          <td align="center"> 0.28 </td>
          <td align="center"> 2.23 </td>
        </tr>
        </tr>
      </tbody>
    </table>

    <br>
    <h2>File hierarchy</h2>
    <pre>
      ├── metadata
      │   ├── generate_shapenetsem_split_new.ipynb
      │   └── shapenetsem001_train_test_new.json
      ├── test
      ├── train
      │   ├── 1511489148409439
      │   ├── 3527550462177290
      │   |   ├──img.png
      │   |   ├──info.json
      │   |   ├──seg.png
      │   |   └──seginds
      │   |      ├──0.png
      │   |      ├──1.png
      │   |      └── ...
      │   ├──4109417696451021
      │   └── ...
      └── val
</pre>


    <h2 style="margin-top:0.75cm;">BibTeX</h2>
    <pre>    @article{hobley2023abc,
        title={ABC Easy as 123: A Blind Counter for Exemplar-Free Multi-Class Class-agnostic Counting},
        author={Hobley, Michael and Prisacariu, Victor},
        journal={arXiv preprint arXiv:2309.04820},
        year={2023}}
  </pre>

  </main>

</body>

</html>